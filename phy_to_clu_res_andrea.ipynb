{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables may change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basedir=\"/mnt/adata9/processing/\"\n",
    "basedir = \"/home/acumpeli/adata_laptop/mnt/adata9/processing/\"\n",
    "\n",
    "animal_name='JC283'\n",
    "date='20220910'\n",
    "\n",
    "# mbasedir=\"/mnt/adata9/merged/m\"+animal_name+'-'+date+'/'\n",
    "mbasedir=\"/home/acumpeli/adata_laptop/mnt/adata9/merged/m\"+animal_name+'-'+date+'/'\n",
    "\n",
    "num_tetrodes=25\n",
    "last_pfc_left=8\n",
    "last_pfc_right=15\n",
    "\n",
    "session_idx=[[1],[2,3,4],[5],[6],[7]]\n",
    "\n",
    "# Possible brain regions and cell types\n",
    "brain_regions = ['1', 'p', 'r', 'o', 'c']\n",
    "cell_types = ['b', 'p']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables do not change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_names=['presleep','training1','intersleep','training2','postsleep']\n",
    "\n",
    "sample_rate_res_old=24000\n",
    "\n",
    "sample_rate_whl=39.0625\n",
    "sample_rate_res=20000\n",
    "\n",
    "downsample_res=sample_rate_res/sample_rate_res_old\n",
    "\n",
    "cell_ind=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tet0\n",
      "Processing tet1\n",
      "Processing tet2\n",
      "Processing tet3\n",
      "Tetrode folder missing\n",
      "Processing tet4\n",
      "Processing tet5\n",
      "Processing tet6\n",
      "Processing tet7\n",
      "Processing tet8\n",
      "Processing tet9\n",
      "Processing tet10\n",
      "Processing tet11\n",
      "Processing tet12\n",
      "Processing tet13\n",
      "Processing tet14\n",
      "Processing tet15\n",
      "Processing tet16\n",
      "Processing tet17\n",
      "Processing tet18\n",
      "Tetrode folder missing\n",
      "Processing tet19\n",
      "Processing tet20\n",
      "Processing tet21\n",
      "Processing tet22\n",
      "Processing tet23\n",
      "Processing tet24\n"
     ]
    }
   ],
   "source": [
    "# If the merged animal directory does not exist, create it\n",
    "if not os.path.isdir(mbasedir):\n",
    "        os.makedirs(mbasedir)\n",
    "\n",
    "# Create a directory for this session\n",
    "mfolder=basedir+animal_name+'/m'+animal_name+'-'+date+'/'\n",
    "\n",
    "# Initialize the output res, clu, and des variables\n",
    "res=np.zeros([0])\n",
    "clu=np.zeros([0])\n",
    "des=[]\n",
    "\n",
    "des_full=[]\n",
    "\n",
    "\n",
    "for tet_i in range(num_tetrodes):\n",
    "    print(\"Processing tet\"+str(tet_i))\n",
    "    folder=basedir+animal_name+'/'+date+'/sorted/tet'+str(tet_i)+'/phy_export/'\n",
    "    \n",
    "    # If tetrode folder exists, continue:\n",
    "    if os.path.isdir(folder)==True:\n",
    "        \n",
    "        # Load phy spike clusters and times\n",
    "        spike_clusters=np.load(folder+'spike_clusters.npy')\n",
    "        spike_times=np.load(folder+'spike_times.npy')\n",
    "\n",
    "        # Load information about clusters (whether good, noise, or mua)\n",
    "        good_noise=pd.read_csv(folder+'cluster_group.tsv',sep='\\t').to_numpy()\n",
    "\n",
    "        good_ind=np.zeros([0])\n",
    "        mua_ind=np.zeros([0])\n",
    "\n",
    "        # Iterate over clusters and keep good and mua clusters\n",
    "        for i in range(good_noise.shape[0]):\n",
    "            if good_noise[i,1]=='good' or good_noise[i,1]=='mua':\n",
    "                neurontype=pd.read_csv(folder+'cluster_neurontype.tsv',sep='\\t').to_numpy()\n",
    "                good_ind=np.append(good_ind,good_noise[i,0])\n",
    "                if good_noise[i,1]=='mua':\n",
    "                    mua_ind=np.append(mua_ind,1)\n",
    "                else:\n",
    "                    mua_ind=np.append(mua_ind,0)\n",
    "\n",
    "        # For good clusters, export neuron type label to des file and brain area to des_full\n",
    "        for cell_i in range(len(good_ind)):\n",
    "            cluster_idx = np.where(neurontype[:,0] == good_ind[cell_i])\n",
    "            cluster_label=neurontype[cluster_idx,1][0][0]\n",
    "            cell_type = cluster_label[0]\n",
    "            \n",
    "            # Make sure the cell label makes sense and append to des\n",
    "            if (\n",
    "                cluster_label[0] in cell_types\n",
    "                and cluster_label[1] in brain_regions\n",
    "                and len(cluster_label)==2\n",
    "                ):\n",
    "                \n",
    "                des.append(neurontype_i)\n",
    "                \n",
    "                # Append to des_full based on brain region\n",
    "                if tet_i<last_pfc_left:\n",
    "                    des_full.append('pfc_left')\n",
    "                elif tet_i<last_pfc_right:\n",
    "                    des_full.append('pfc_right')\n",
    "                else:\n",
    "                    des_full.append('hpc_right')\n",
    "                    \n",
    "            else:\n",
    "                print('Check label for cluster', cell_i)\n",
    "                break\n",
    "\n",
    "            res_t=spike_times[spike_clusters==good_ind[cell_i]]\n",
    "            clu_t=cell_ind*np.ones(len(res_t))\n",
    "\n",
    "            if mua_ind[cell_i]==1:\n",
    "                clu_t=np.ones(len(clu_t))\n",
    "\n",
    "            res=np.append(res,res_t)\n",
    "            clu=np.append(clu,clu_t)\n",
    "\n",
    "            cell_ind=cell_ind+1\n",
    "\n",
    "        else:\n",
    "            print('Tetrode folder missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whl new creation\n",
    "\n",
    "session_shift=np.loadtxt(basedir+animal_name+'/'+date+'/'+'session_shifts.txt')\n",
    "session_shift=np.append([0],session_shift)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(basedir+animal_name+'/'+date+'/'+date+'.whl',\n",
    "                                        sep=' ', header=None, names=['dim1', 'dim2', 'dim1_2', 'dim2_2', 'timestamp','valid'])\n",
    "\n",
    "whl_old=pd.DataFrame(df).to_numpy()\n",
    "length_time_whl=whl_old.shape[0]/50/60/60\n",
    "\n",
    "len_session=session_shift[-1]\n",
    "length_time=len_session/sample_rate_res_old/60/60\n",
    "\n",
    "data_points_len=(len_session)/whl_old.shape[0]\n",
    "sample_rate_whl_old=data_points_len/sample_rate_res_old\n",
    "\n",
    "\n",
    "sample_rate_whl_old=1/sample_rate_whl_old\n",
    "\n",
    "\n",
    "\n",
    "x_old=np.linspace(0,len_session,whl_old.shape[0])\n",
    "x_new=np.linspace(0,len_session,int(whl_old.shape[0]/sample_rate_whl_old*sample_rate_whl))\n",
    "\n",
    "whl_new=np.zeros([len(x_new),2])\n",
    "\n",
    "#dim1\n",
    "f = interpolate.interp1d(x_old, whl_old[:,0])\n",
    "y_new=f(x_new)\n",
    "whl_new[:,0] = f(x_new)\n",
    "#dim2\n",
    "f = interpolate.interp1d(x_old, whl_old[:,1])\n",
    "whl_new[:,1] = f(x_new)\n",
    "\n",
    "#add -1 for missing\n",
    "index_bad_new=np.zeros(len(x_new))\n",
    "for i in range(whl_old.shape[0]):\n",
    "    if whl_old[i,0]==1023:\n",
    "        i_new=int(i/sample_rate_whl_old*sample_rate_whl)\n",
    "        if i_new+1>len(index_bad_new)-1:\n",
    "            index_bad_new[i_new-1:i_new]=1\n",
    "        else:\n",
    "            index_bad_new[i_new-2:i_new+2]=1\n",
    "\n",
    "\n",
    "whl_new[index_bad_new>0,:]=1023\n",
    "\n",
    "\n",
    "#np.savetxt(mfolder+animal_name+'-'+date+'_'+str(session_i)+'.whl', whl_new.astype(int), fmt='%i')\n",
    "\n",
    "\n",
    "\n",
    "sort_arg=np.argsort(res)\n",
    "\n",
    "res=res[sort_arg]\n",
    "clu=clu[sort_arg]\n",
    "\n",
    "res_down=res*downsample_res\n",
    "session_shift_down=session_shift*downsample_res\n",
    "\n",
    "##########################\n",
    "print(session_shift_down)\n",
    "\n",
    "for i in range(len(session_idx)):\n",
    "\n",
    "    start_cut=session_idx[i][0]-1\n",
    "    end_cut=session_idx[i][-1]\n",
    "    \n",
    "    ##############################################################\n",
    "    print(start_cut, end_cut)\n",
    "    print(session_idx)\n",
    "    \n",
    "    index1=res_down<session_shift_down[end_cut]\n",
    "    index2=res_down>session_shift_down[start_cut]\n",
    "    #test=np.logical_and(index1,index2)\n",
    "    clu_temp=clu[np.logical_and(res_down<session_shift_down[end_cut],res_down>session_shift_down[start_cut])]\n",
    "    res_temp=res_down[np.logical_and(res_down<session_shift_down[end_cut],res_down>session_shift_down[start_cut])]\n",
    "\n",
    "    res_temp=res_temp-session_shift_down[start_cut]\n",
    "    clu_temp = np.insert(clu_temp, 0, cell_ind, axis=0)\n",
    "\n",
    "\n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.res', res_temp.astype(int), fmt='%i')\n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.clu', clu_temp.astype(int), fmt='%i')\n",
    "\n",
    "    start_whl=int(session_shift_down[start_cut]/sample_rate_res*sample_rate_whl)\n",
    "    end_whl=int(session_shift_down[end_cut]/sample_rate_res*sample_rate_whl)\n",
    "    whl_temp=whl_new[start_whl:end_whl]\n",
    "\n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.whl', whl_temp.astype(int), fmt='%i')\n",
    "\n",
    "    plt.plot(whl_temp[:,0],whl_temp[:,1],'*')\n",
    "    plt.xlim([0,200])\n",
    "    plt.ylim([0,200])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "with open(mbasedir+animal_name+'-'+date+'.des', 'w') as fp:\n",
    "    fp.write('\\n'.join(des))\n",
    "\n",
    "with open(mbasedir+animal_name+'-'+date+'.des_full', 'w') as fp:\n",
    "    fp.write('\\n'.join(des_full))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
