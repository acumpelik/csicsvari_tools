{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "These variables may change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "basedir = \"/mnt/adata9/processing/\"\n",
    "\n",
    "animal_name='JC258'\n",
    "date='20210626'\n",
    "\n",
    "mbasedir=\"/adata_pool/merged/\"+animal_name+'-'+date+'/'\n",
    "\n",
    "num_tetrodes=27\n",
    "last_pfc_left=8 # index of last tetrode plus 1\n",
    "last_pfc_right=14\n",
    "\n",
    "session_idx=[[1],[2],[3]]\n",
    "\n",
    "# Possible brain regions and cell types\n",
    "brain_regions = ['1', 'p', 'r', 'o', 'c']\n",
    "cell_types = ['b', 'p']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables do not change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_names=['presleep','training1','intersleep','training2','postsleep']\n",
    "session_names=['training1','intersleep','training2']\n",
    "\n",
    "sample_rate_res_old=24000\n",
    "\n",
    "sample_rate_whl=39.0625\n",
    "sample_rate_res=20000\n",
    "\n",
    "downsampled_res=sample_rate_res/sample_rate_res_old\n",
    "\n",
    "starting_cell_ind=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Des file generation\n",
    "The des file contains information about the neuron type and the brain area. The des_full file contains information about the brain hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tet0\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet1\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet2\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "Processing tet3\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "[['pp']]\n",
      "Current cell_i: 1\n",
      "Processing tet4\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "Processing tet5\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet6\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "Processing tet7\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "[['pp']]\n",
      "Current cell_i: 1\n",
      "[['pp']]\n",
      "Current cell_i: 2\n",
      "Processing tet8\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "Processing tet9\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "Processing tet10\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet11\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "[['pp']]\n",
      "Current cell_i: 1\n",
      "[['pp']]\n",
      "Current cell_i: 2\n",
      "[['pp']]\n",
      "Current cell_i: 3\n",
      "[['pp']]\n",
      "Current cell_i: 4\n",
      "[['pp']]\n",
      "Current cell_i: 5\n",
      "[['pp']]\n",
      "Current cell_i: 6\n",
      "Processing tet12\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "Processing tet13\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "[['pp']]\n",
      "Current cell_i: 1\n",
      "[['pp']]\n",
      "Current cell_i: 2\n",
      "[['pp']]\n",
      "Current cell_i: 3\n",
      "[['pp']]\n",
      "Current cell_i: 4\n",
      "[['pp']]\n",
      "Current cell_i: 5\n",
      "[['pp']]\n",
      "Current cell_i: 6\n",
      "[['pp']]\n",
      "Current cell_i: 7\n",
      "[['pp']]\n",
      "Current cell_i: 8\n",
      "[['pp']]\n",
      "Current cell_i: 9\n",
      "[['pp']]\n",
      "Current cell_i: 10\n",
      "[['pp']]\n",
      "Current cell_i: 11\n",
      "[['pp']]\n",
      "Current cell_i: 12\n",
      "[['pp']]\n",
      "Current cell_i: 13\n",
      "Processing tet14\n",
      "Length of mua_ind before loop: 0\n",
      "[['pp']]\n",
      "Current cell_i: 0\n",
      "Processing tet15\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet16\n",
      "Length of mua_ind before loop: 0\n",
      "[['p1']]\n",
      "Current cell_i: 0\n",
      "[['p1']]\n",
      "Current cell_i: 1\n",
      "[['p1']]\n",
      "Current cell_i: 2\n",
      "Processing tet17\n",
      "Length of mua_ind before loop: 0\n",
      "[['p1']]\n",
      "Current cell_i: 0\n",
      "[['p1']]\n",
      "Current cell_i: 1\n",
      "Processing tet18\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet19\n",
      "Length of mua_ind before loop: 0\n",
      "[['pc']]\n",
      "Current cell_i: 0\n",
      "[['pc']]\n",
      "Current cell_i: 1\n",
      "[['bc']]\n",
      "Current cell_i: 2\n",
      "[['pc']]\n",
      "Current cell_i: 3\n",
      "[['pc']]\n",
      "Current cell_i: 4\n",
      "[['pc']]\n",
      "Current cell_i: 5\n",
      "[['pc']]\n",
      "Current cell_i: 6\n",
      "[['pc']]\n",
      "Current cell_i: 7\n",
      "[['pc']]\n",
      "Current cell_i: 8\n",
      "[['pc']]\n",
      "Current cell_i: 9\n",
      "[['pc']]\n",
      "Current cell_i: 10\n",
      "[['pc']]\n",
      "Current cell_i: 11\n",
      "[['pc']]\n",
      "Current cell_i: 12\n",
      "[['pc']]\n",
      "Current cell_i: 13\n",
      "Processing tet20\n",
      "Length of mua_ind before loop: 0\n",
      "[['p1']]\n",
      "Current cell_i: 0\n",
      "Processing tet21\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet22\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet23\n",
      "Length of mua_ind before loop: 0\n",
      "Processing tet24\n",
      "Length of mua_ind before loop: 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/adata9/processing/JC258/20210626/sorted/tet24/phy_export/cluster_neurontype.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40073/1070225855.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_noise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgood_noise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'good'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgood_noise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'mua'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mneurontype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'cluster_neurontype.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mgood_ind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgood_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgood_noise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgood_noise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'mua'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/adata9/processing/JC258/20210626/sorted/tet24/phy_export/cluster_neurontype.tsv'"
     ]
    }
   ],
   "source": [
    "# If the merged animal directory does not exist, create it\n",
    "if not os.path.isdir(mbasedir):\n",
    "        os.makedirs(mbasedir)\n",
    "\n",
    "# Create a directory for this session\n",
    "mfolder=basedir+animal_name+'/m'+animal_name+'-'+date+'/'\n",
    "\n",
    "# Initialize the output res, clu, and des variables\n",
    "res=np.zeros([0])\n",
    "clu=np.zeros([0])\n",
    "des=[]\n",
    "\n",
    "des_full=[]\n",
    "\n",
    "for tet_i in range(num_tetrodes):\n",
    "    print(\"Processing tet\"+str(tet_i))\n",
    "    folder=basedir+animal_name+'/'+date+'/sorted/tet'+str(tet_i)+'/phy_export/'\n",
    "    \n",
    "    # If tetrode folder exists, continue:\n",
    "    if os.path.isdir(folder)==True:\n",
    "        \n",
    "        # Load phy spike clusters and times\n",
    "        spike_clusters=np.load(folder+'spike_clusters.npy')\n",
    "        spike_times=np.load(folder+'spike_times.npy')\n",
    "\n",
    "        # Load information about clusters (whether good, noise, or mua)\n",
    "        good_noise=pd.read_csv(folder+'cluster_group.tsv',sep='\\t').to_numpy()\n",
    "\n",
    "        good_ind=np.zeros([0])\n",
    "        mua_ind=np.zeros([0])\n",
    "        ###################################\n",
    "        print(\"Length of mua_ind before loop:\", len(mua_ind))\n",
    "\n",
    "        # Iterate over clusters and keep good and mua clusters\n",
    "        for i in range(good_noise.shape[0]):\n",
    "            if good_noise[i,1]=='good' or good_noise[i,1]=='mua':\n",
    "                neurontype=pd.read_csv(folder+'cluster_neurontype.tsv',sep='\\t').to_numpy()\n",
    "                good_ind=np.append(good_ind,good_noise[i,0])\n",
    "                if good_noise[i,1]=='mua':\n",
    "                    mua_ind=np.append(mua_ind,1)\n",
    "                else:\n",
    "                    mua_ind=np.append(mua_ind,0)\n",
    "                    \n",
    "#         ### Shaurya's edit\n",
    "#         ### I THINK IT SHOULD BE THIS              \n",
    "#         # Iterate over clusters and keep good and mua clusters\n",
    "        \n",
    "        \n",
    "#         for i in range(good_noise.shape[0]):\n",
    "#             if good_noise[i,1]=='good':\n",
    "#                 neurontype=pd.read_csv(folder+'cluster_neurontype.tsv',sep='\\t').to_numpy()\n",
    "#                 good_ind=np.append(good_ind,good_noise[i,0])\n",
    "#             elif good_noise[i,1]=='mua':\n",
    "#                 mua_ind=np.append(mua_ind,1)\n",
    "#             else:\n",
    "#                 mua_ind=np.append(mua_ind,0)\n",
    "#         print(good_ind)\n",
    "#         print(mua_ind)\n",
    "        # For good clusters, export neuron type label to des file and brain area to des_full\n",
    "        for cell_i in range(len(good_ind)):\n",
    "            cluster_idx = np.where(neurontype[:,0] == good_ind[cell_i])\n",
    "            print(neurontype[cluster_idx,1])\n",
    "            cluster_label=neurontype[cluster_idx,1][0][0]\n",
    "            cell_type = cluster_label[0]\n",
    "            \n",
    "            # Make sure the cell label makes sense and append to des\n",
    "            if (\n",
    "                cluster_label[0] in cell_types\n",
    "                and cluster_label[1] in brain_regions\n",
    "                and len(cluster_label)==2\n",
    "                ):\n",
    "                \n",
    "                des.append(cluster_label)\n",
    "                \n",
    "                # Append to des_full based on brain region\n",
    "                if tet_i<last_pfc_left:\n",
    "                    des_full.append('pfc_left')\n",
    "                elif tet_i<last_pfc_right:\n",
    "                    des_full.append('pfc_right')\n",
    "                else:\n",
    "                    des_full.append('hpc_right')\n",
    "                    \n",
    "            else:\n",
    "                print('Check label for cluster', cell_i)\n",
    "                break\n",
    "\n",
    "            res_t=spike_times[spike_clusters==good_ind[cell_i]]\n",
    "            clu_t=starting_cell_ind*np.ones(len(res_t))\n",
    "            \n",
    "            print(\"Current cell_i:\", cell_i)\n",
    "            \n",
    "            if mua_ind[cell_i]==1:\n",
    "                clu_t=np.ones(len(clu_t))\n",
    "\n",
    "            res=np.append(res,res_t)\n",
    "            clu=np.append(clu,clu_t)\n",
    "\n",
    "            starting_cell_ind=starting_cell_ind+1\n",
    "\n",
    "    else:\n",
    "        print('Tetrode folder missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and interpolating of the whl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timestamps for each recording\n",
    "session_timestamps=np.loadtxt(basedir+animal_name+'/'+date+'/'+'session_shifts.txt')\n",
    "session_timestamps=np.append([0],session_timestamps) # start the first timestamp at 0\n",
    "\n",
    "# Load the whl file and interpolate\n",
    "df = pd.read_csv(basedir+animal_name+'/'+date+'/'+date+'.whl',\n",
    "                                        sep=' ', header=None, names=['dim1', 'dim2', 'dim1_2', 'dim2_2', 'timestamp','valid'])\n",
    "\n",
    "whl_old=pd.DataFrame(df).to_numpy()\n",
    "length_time_whl=whl_old.shape[0]/50/60/60\n",
    "\n",
    "len_session=session_timestamps[-1]\n",
    "length_time=len_session/sample_rate_res_old/60/60\n",
    "\n",
    "data_points_len=(len_session)/whl_old.shape[0]\n",
    "sample_rate_whl_old=data_points_len/sample_rate_res_old\n",
    "\n",
    "sample_rate_whl_old=1/sample_rate_whl_old\n",
    "\n",
    "\n",
    "x_old=np.linspace(0,len_session,whl_old.shape[0])\n",
    "x_new=np.linspace(0,len_session,int(whl_old.shape[0]/sample_rate_whl_old*sample_rate_whl))\n",
    "\n",
    "whl_new=np.zeros([len(x_new),2])\n",
    "\n",
    "# dim1\n",
    "f = interpolate.interp1d(x_old, whl_old[:,0])\n",
    "y_new=f(x_new)\n",
    "whl_new[:,0] = f(x_new)\n",
    "\n",
    "# dim2\n",
    "f = interpolate.interp1d(x_old, whl_old[:,1])\n",
    "whl_new[:,1] = f(x_new)\n",
    "\n",
    "# replace missing timestamps with -1\n",
    "index_bad_new=np.zeros(len(x_new))\n",
    "for i in range(whl_old.shape[0]):\n",
    "    if whl_old[i,0]==1023:\n",
    "        i_new=int(i/sample_rate_whl_old*sample_rate_whl)\n",
    "        if i_new+1>len(index_bad_new)-1:\n",
    "            index_bad_new[i_new-1:i_new]=1\n",
    "        else:\n",
    "            index_bad_new[i_new-2:i_new+2]=1\n",
    "\n",
    "whl_new[index_bad_new>0,:]=1023\n",
    "\n",
    "# I don't know what this line is, Vlad had it commented out\n",
    "# np.savetxt(mfolder+animal_name+'-'+date+'_'+str(session_i)+'.whl', whl_new.astype(int), fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whl, res and clu file splitting\n",
    "Splitting according to session type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sort_arg=np.argsort(res)\n",
    "\n",
    "res=res[sort_arg]\n",
    "clu=clu[sort_arg]\n",
    "\n",
    "res_down=res*downsampled_res\n",
    "session_timestamps_down=session_timestamps*downsampled_res\n",
    "\n",
    "\n",
    "for i in range(len(session_idx)):\n",
    "\n",
    "    # Return the first and last recording of a session type\n",
    "    start_cut=session_idx[i][0]-1\n",
    "    end_cut=session_idx[i][-1]\n",
    "    \n",
    "    index1=res_down<session_timestamps_down[end_cut]\n",
    "    index2=res_down>session_timestamps_down[start_cut]\n",
    "    #test=np.logical_and(index1,index2)\n",
    "    clu_temp=clu[np.logical_and(res_down<session_timestamps_down[end_cut],res_down>session_timestamps_down[start_cut])]\n",
    "    res_temp=res_down[np.logical_and(res_down<session_timestamps_down[end_cut],res_down>session_timestamps_down[start_cut])]\n",
    "\n",
    "    res_temp=res_temp-session_timestamps_down[start_cut]\n",
    "    clu_temp = np.insert(clu_temp, 0, starting_cell_ind, axis=0)\n",
    "    \n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.res', res_temp.astype(int), fmt='%i')\n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.clu', clu_temp.astype(int), fmt='%i')\n",
    "\n",
    "    start_whl=int(session_timestamps_down[start_cut]/sample_rate_res*sample_rate_whl)\n",
    "    end_whl=int(session_timestamps_down[end_cut]/sample_rate_res*sample_rate_whl)\n",
    "    whl_temp=whl_new[start_whl:end_whl]\n",
    "\n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.whl', whl_temp.astype(int), fmt='%i')\n",
    "\n",
    "    plt.plot(whl_temp[:,0],whl_temp[:,1],'*')\n",
    "    plt.xlim([0,200])\n",
    "    plt.ylim([0,200])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "with open(mbasedir+animal_name+'-'+date+'.des', 'w') as fp:\n",
    "    fp.write('\\n'.join(des))\n",
    "\n",
    "with open(mbasedir+animal_name+'-'+date+'.des_full', 'w') as fp:\n",
    "    fp.write('\\n'.join(des_full))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
