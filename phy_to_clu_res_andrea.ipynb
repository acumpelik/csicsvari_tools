{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "These variables may change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "basedir=\"/mnt/adata9/processing/\"\n",
    "# basedir = \"/home/acumpeli/adata_laptop/mnt/adata9/processing/\"\n",
    "\n",
    "animal_name='JC283'\n",
    "date='20220910'\n",
    "\n",
    "mbasedir=\"/mnt/adata9/merged/m\"+animal_name+'-'+date+'/'\n",
    "# mbasedir=\"/home/acumpeli/adata_laptop/mnt/adata9/merged/m\"+animal_name+'-'+date+'/'\n",
    "\n",
    "num_tetrodes=25\n",
    "last_pfc_left=8\n",
    "last_pfc_right=15\n",
    "\n",
    "session_idx=[[1],[2,3,4],[5],[6],[7]]\n",
    "\n",
    "# Possible brain regions and cell types\n",
    "brain_regions = ['1', 'p', 'r', 'o', 'c']\n",
    "cell_types = ['b', 'p']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables do not change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_names=['presleep','training1','intersleep','training2','postsleep']\n",
    "\n",
    "sample_rate_res_old=24000\n",
    "\n",
    "sample_rate_whl=39.0625\n",
    "sample_rate_res=20000\n",
    "\n",
    "downsampled_res=sample_rate_res/sample_rate_res_old\n",
    "\n",
    "starting_cell_ind=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Des file generation\n",
    "The des file contains information about the neuron type and the brain area. The des_full file contains information about the brain hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tet0\n",
      "Length of mua_ind before loop: 0\n",
      "Current cell_i: 0\n",
      "Current cell_i: 1\n",
      "Current cell_i: 2\n",
      "Current cell_i: 3\n",
      "Current cell_i: 4\n",
      "Current cell_i: 5\n",
      "Current cell_i: 6\n",
      "Current cell_i: 7\n",
      "Processing tet1\n",
      "Length of mua_ind before loop: 0\n",
      "Current cell_i: 0\n",
      "Current cell_i: 1\n",
      "Current cell_i: 2\n",
      "Current cell_i: 3\n",
      "Current cell_i: 4\n",
      "Current cell_i: 5\n",
      "Current cell_i: 6\n",
      "Current cell_i: 7\n",
      "Current cell_i: 8\n",
      "Current cell_i: 9\n",
      "Current cell_i: 10\n",
      "Current cell_i: 11\n",
      "Current cell_i: 12\n",
      "Current cell_i: 13\n",
      "Current cell_i: 14\n",
      "Current cell_i: 15\n",
      "Current cell_i: 16\n",
      "Current cell_i: 17\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 17 is out of bounds for axis 0 with size 17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1893610/2616939149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current cell_i:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmua_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mclu_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclu_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 17 is out of bounds for axis 0 with size 17"
     ]
    }
   ],
   "source": [
    "# If the merged animal directory does not exist, create it\n",
    "if not os.path.isdir(mbasedir):\n",
    "        os.makedirs(mbasedir)\n",
    "\n",
    "# Create a directory for this session\n",
    "mfolder=basedir+animal_name+'/m'+animal_name+'-'+date+'/'\n",
    "\n",
    "# Initialize the output res, clu, and des variables\n",
    "res=np.zeros([0])\n",
    "clu=np.zeros([0])\n",
    "des=[]\n",
    "\n",
    "des_full=[]\n",
    "\n",
    "for tet_i in range(num_tetrodes):\n",
    "    print(\"Processing tet\"+str(tet_i))\n",
    "    folder=basedir+animal_name+'/'+date+'/sorted/tet'+str(tet_i)+'/phy_export/'\n",
    "    \n",
    "    # If tetrode folder exists, continue:\n",
    "    if os.path.isdir(folder)==True:\n",
    "        \n",
    "        # Load phy spike clusters and times\n",
    "        spike_clusters=np.load(folder+'spike_clusters.npy')\n",
    "        spike_times=np.load(folder+'spike_times.npy')\n",
    "\n",
    "        # Load information about clusters (whether good, noise, or mua)\n",
    "        good_noise=pd.read_csv(folder+'cluster_group.tsv',sep='\\t').to_numpy()\n",
    "\n",
    "        good_ind=np.zeros([0])\n",
    "        mua_ind=np.zeros([0])\n",
    "        ###################################\n",
    "        print(\"Length of mua_ind before loop:\", len(mua_ind))\n",
    "\n",
    "        # Iterate over clusters and keep good and mua clusters\n",
    "        for i in range(good_noise.shape[0]):\n",
    "            if good_noise[i,1]=='good' or good_noise[i,1]=='mua':\n",
    "                neurontype=pd.read_csv(folder+'cluster_neurontype.tsv',sep='\\t').to_numpy()\n",
    "                good_ind=np.append(good_ind,good_noise[i,0])\n",
    "                if good_noise[i,1]=='mua':\n",
    "                    mua_ind=np.append(mua_ind,1)\n",
    "                else:\n",
    "                    mua_ind=np.append(mua_ind,0)\n",
    "                    \n",
    "        ### Shaurya's edit\n",
    "        ### I THINK IT SHOULD BE THIS              \n",
    "        # Iterate over clusters and keep good and mua clusters\n",
    "\n",
    "        for i in range(good_noise.shape[0]):\n",
    "            if good_noise[i,1]=='good':\n",
    "                neurontype=pd.read_csv(folder+'cluster_neurontype.tsv',sep='\\t').to_numpy()\n",
    "                good_ind=np.append(good_ind,good_noise[i,0])\n",
    "            elif good_noise[i,1]=='mua':\n",
    "                mua_ind=np.append(mua_ind,1)\n",
    "            else:\n",
    "                mua_ind=np.append(mua_ind,0)\n",
    "\n",
    "        # For good clusters, export neuron type label to des file and brain area to des_full\n",
    "        for cell_i in range(len(good_ind)):\n",
    "            cluster_idx = np.where(neurontype[:,0] == good_ind[cell_i])\n",
    "            cluster_label=neurontype[cluster_idx,1][0][0]\n",
    "            cell_type = cluster_label[0]\n",
    "            \n",
    "            # Make sure the cell label makes sense and append to des\n",
    "            if (\n",
    "                cluster_label[0] in cell_types\n",
    "                and cluster_label[1] in brain_regions\n",
    "                and len(cluster_label)==2\n",
    "                ):\n",
    "                \n",
    "                des.append(cluster_label)\n",
    "                \n",
    "                # Append to des_full based on brain region\n",
    "                if tet_i<last_pfc_left:\n",
    "                    des_full.append('pfc_left')\n",
    "                elif tet_i<last_pfc_right:\n",
    "                    des_full.append('pfc_right')\n",
    "                else:\n",
    "                    des_full.append('hpc_right')\n",
    "                    \n",
    "            else:\n",
    "                print('Check label for cluster', cell_i)\n",
    "                break\n",
    "\n",
    "            res_t=spike_times[spike_clusters==good_ind[cell_i]]\n",
    "            clu_t=starting_cell_ind*np.ones(len(res_t))\n",
    "            \n",
    "            print(\"Current cell_i:\", cell_i)\n",
    "            \n",
    "            if mua_ind[cell_i]==1:\n",
    "                clu_t=np.ones(len(clu_t))\n",
    "\n",
    "            res=np.append(res,res_t)\n",
    "            clu=np.append(clu,clu_t)\n",
    "\n",
    "            starting_cell_ind=starting_cell_ind+1\n",
    "\n",
    "    else:\n",
    "        print('Tetrode folder missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling and interpolating of the whl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timestamps for each recording\n",
    "session_timestamps=np.loadtxt(basedir+animal_name+'/'+date+'/'+'session_shifts.txt')\n",
    "session_timestamps=np.append([0],session_timestamps) # start the first timestamp at 0\n",
    "\n",
    "# Load the whl file and interpolate\n",
    "df = pd.read_csv(basedir+animal_name+'/'+date+'/'+date+'.whl',\n",
    "                                        sep=' ', header=None, names=['dim1', 'dim2', 'dim1_2', 'dim2_2', 'timestamp','valid'])\n",
    "\n",
    "whl_old=pd.DataFrame(df).to_numpy()\n",
    "length_time_whl=whl_old.shape[0]/50/60/60\n",
    "\n",
    "len_session=session_timestamps[-1]\n",
    "length_time=len_session/sample_rate_res_old/60/60\n",
    "\n",
    "data_points_len=(len_session)/whl_old.shape[0]\n",
    "sample_rate_whl_old=data_points_len/sample_rate_res_old\n",
    "\n",
    "sample_rate_whl_old=1/sample_rate_whl_old\n",
    "\n",
    "\n",
    "x_old=np.linspace(0,len_session,whl_old.shape[0])\n",
    "x_new=np.linspace(0,len_session,int(whl_old.shape[0]/sample_rate_whl_old*sample_rate_whl))\n",
    "\n",
    "whl_new=np.zeros([len(x_new),2])\n",
    "\n",
    "# dim1\n",
    "f = interpolate.interp1d(x_old, whl_old[:,0])\n",
    "y_new=f(x_new)\n",
    "whl_new[:,0] = f(x_new)\n",
    "\n",
    "# dim2\n",
    "f = interpolate.interp1d(x_old, whl_old[:,1])\n",
    "whl_new[:,1] = f(x_new)\n",
    "\n",
    "# replace missing timestamps with -1\n",
    "index_bad_new=np.zeros(len(x_new))\n",
    "for i in range(whl_old.shape[0]):\n",
    "    if whl_old[i,0]==1023:\n",
    "        i_new=int(i/sample_rate_whl_old*sample_rate_whl)\n",
    "        if i_new+1>len(index_bad_new)-1:\n",
    "            index_bad_new[i_new-1:i_new]=1\n",
    "        else:\n",
    "            index_bad_new[i_new-2:i_new+2]=1\n",
    "\n",
    "whl_new[index_bad_new>0,:]=1023\n",
    "\n",
    "# I don't know what this line is, Vlad had it commented out\n",
    "# np.savetxt(mfolder+animal_name+'-'+date+'_'+str(session_i)+'.whl', whl_new.astype(int), fmt='%i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whl, res and clu file splitting\n",
    "Splitting according to session type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sort_arg=np.argsort(res)\n",
    "\n",
    "res=res[sort_arg]\n",
    "clu=clu[sort_arg]\n",
    "\n",
    "res_down=res*downsampled_res\n",
    "session_timestamps_down=session_timestamps*downsampled_res\n",
    "\n",
    "\n",
    "for i in range(len(session_idx)):\n",
    "\n",
    "    # Return the first and last recording of a session type\n",
    "    start_cut=session_idx[i][0]-1\n",
    "    end_cut=session_idx[i][-1]\n",
    "    \n",
    "    index1=res_down<session_timestamps_down[end_cut]\n",
    "    index2=res_down>session_timestamps_down[start_cut]\n",
    "    #test=np.logical_and(index1,index2)\n",
    "    clu_temp=clu[np.logical_and(res_down<session_timestamps_down[end_cut],res_down>session_timestamps_down[start_cut])]\n",
    "    res_temp=res_down[np.logical_and(res_down<session_timestamps_down[end_cut],res_down>session_timestamps_down[start_cut])]\n",
    "\n",
    "    res_temp=res_temp-session_timestamps_down[start_cut]\n",
    "    clu_temp = np.insert(clu_temp, 0, starting_cell_ind, axis=0)\n",
    "    \n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.res', res_temp.astype(int), fmt='%i')\n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.clu', clu_temp.astype(int), fmt='%i')\n",
    "\n",
    "    start_whl=int(session_timestamps_down[start_cut]/sample_rate_res*sample_rate_whl)\n",
    "    end_whl=int(session_timestamps_down[end_cut]/sample_rate_res*sample_rate_whl)\n",
    "    whl_temp=whl_new[start_whl:end_whl]\n",
    "\n",
    "    np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.whl', whl_temp.astype(int), fmt='%i')\n",
    "\n",
    "    plt.plot(whl_temp[:,0],whl_temp[:,1],'*')\n",
    "    plt.xlim([0,200])\n",
    "    plt.ylim([0,200])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "with open(mbasedir+animal_name+'-'+date+'.des', 'w') as fp:\n",
    "    fp.write('\\n'.join(des))\n",
    "\n",
    "with open(mbasedir+animal_name+'-'+date+'.des_full', 'w') as fp:\n",
    "    fp.write('\\n'.join(des_full))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
