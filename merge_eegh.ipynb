{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "These variables may change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "basedir = \"/mnt/adata9/\"\n",
    "\n",
    "animal_name='JC274'\n",
    "date='20220304'\n",
    "\n",
    "mbasedir=\"/adata_pool/merged/\"+animal_name+'-'+date+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables do not change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate_res_old=24000\n",
    "\n",
    "sample_rate_whl=39.0625\n",
    "sample_rate_res=20000\n",
    "\n",
    "sample_rate_eegh=5000\n",
    "\n",
    "downsampled_res=sample_rate_res/sample_rate_res_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import session metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session_metadata = {}\n",
    "with open('session_metadata.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.DictReader(file, delimiter=\";\")    \n",
    "    for line in reader:\n",
    "        session_id = line.pop('session_id')\n",
    "        session_metadata[session_id] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_tetr': '25',\n",
       " 'last_pfc_left': '8',\n",
       " 'last_pfc_right': '14',\n",
       " 'session_names': \"['training1','intersleep','training2']\",\n",
       " 'session_idx': '[[1,2],[3],[4]]',\n",
       " 'reward_arms': '7,3',\n",
       " 'rewards': 'C,H'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basename = animal_name+'-'+date\n",
    "session_metadata[basename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_tetrodes = int(session_metadata[basename]['num_tetr'])\n",
    "\n",
    "session_idx = json.loads(session_metadata[basename]['session_idx'])\n",
    "\n",
    "session_names_str = session_metadata[basename]['session_names']\n",
    "session_names_str = session_names_str.replace(\"'\",'\"') # the single quotes aren't being read in JSON, but I can't use \" in the csv because it's a str delimiter\n",
    "session_names = json.loads(session_names_str)\n",
    "\n",
    "reward_arms_str = session_metadata[basename]['reward_arms']\n",
    "reward_arms = np.array(list(map(int, reward_arms_str.split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_362162/1241191398.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msort_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msort_arg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msort_arg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "sort_arg=np.argsort(res)\n",
    "\n",
    "res=res[sort_arg]\n",
    "clu=clu[sort_arg]\n",
    "\n",
    "res_down=res*downsampled_res\n",
    "session_timestamps_down=session_timestamps*downsampled_res\n",
    "\n",
    "\n",
    "for i in range(len(session_idx)):\n",
    "\n",
    "    # Return the first and last recording of a session type\n",
    "    if len(session_idx[i])>0:\n",
    "        start_cut=session_idx[i][0]-1\n",
    "        end_cut=session_idx[i][-1]\n",
    "\n",
    "        index1=res_down<session_timestamps_down[end_cut]\n",
    "        index2=res_down>session_timestamps_down[start_cut]\n",
    "        #test=np.logical_and(index1,index2)\n",
    "        clu_temp=clu[np.logical_and(res_down<session_timestamps_down[end_cut],res_down>session_timestamps_down[start_cut])]\n",
    "        res_temp=res_down[np.logical_and(res_down<session_timestamps_down[end_cut],res_down>session_timestamps_down[start_cut])]\n",
    "\n",
    "        res_temp=res_temp-session_timestamps_down[start_cut]\n",
    "        clu_temp = np.insert(clu_temp, 0, starting_cell_ind, axis=0)\n",
    "\n",
    "        np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.res', res_temp.astype(int), fmt='%i')\n",
    "        np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.clu', clu_temp.astype(int), fmt='%i')\n",
    "\n",
    "        start_whl=int(session_timestamps_down[start_cut]/sample_rate_res*sample_rate_whl)\n",
    "        end_whl=int(session_timestamps_down[end_cut]/sample_rate_res*sample_rate_whl)\n",
    "        whl_temp=whl_new[start_whl:end_whl]\n",
    "\n",
    "        np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[i]+'.whl', whl_temp.astype(int), fmt='%i')\n",
    "\n",
    "        plt.plot(whl_temp[:,0],whl_temp[:,1],'*')\n",
    "        plt.xlim([0,200])\n",
    "        plt.ylim([0,200])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "with open(mbasedir+animal_name+'-'+date+'.des', 'w') as fp:\n",
    "    fp.write('\\n'.join(des))\n",
    "\n",
    "with open(mbasedir+animal_name+'-'+date+'.des_full', 'w') as fp:\n",
    "    fp.write('\\n'.join(des_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and split eegh files and export reward arm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_files_with_eegh(directory):\n",
    "    eegh_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if 'eegh' in file:\n",
    "                eegh_files.append(os.path.join(root, file))\n",
    "                \n",
    "    return eegh_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basedir='D:\\github/test/'\n",
    "# mbasedir=\"D:\\github/test\\merged\"+animal_name+'-'+date+'/'\n",
    "if not os.path.isdir(mbasedir):\n",
    "    os.makedirs(mbasedir)\n",
    "directory_path_eegh = basedir+\"eeg/\"+animal_name+'/'+date+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find all eegh files in a session\n",
    "eegh_files = sorted(find_files_with_eegh(directory_path_eegh)) # sort the filenames numerically\n",
    "# initialize a merged eegh file and add the first file to it\n",
    "eegh_merged=np.fromfile(eegh_files[0], dtype=np.int16)\n",
    "# reshape the first file (1D to 2D array) so that each row corresponds to one tetrode\n",
    "eegh_merged= eegh_merged.reshape(int(len(eegh_merged)/num_tetrodes),num_tetrodes)\n",
    "\n",
    "# iterate over the other files and add them to the large merged file\n",
    "for eegh_file_i in range(1,len(eegh_files)):\n",
    "    eegh_t=np.fromfile(eegh_files[eegh_file_i], dtype=np.int16)\n",
    "    eegh_t= eegh_t.reshape(int(len(eegh_t)/num_tetrodes),num_tetrodes)\n",
    "    eegh_merged=np.append(eegh_merged,eegh_t,axis=0)\n",
    "\n",
    "# calculate the total length (num timestamps) of the merged eegh file\n",
    "length_eegh_merged=eegh_merged.shape[0]\n",
    "\n",
    "# load the session timestamps and downsample them\n",
    "session_timestamps=np.loadtxt(basedir+\"processing/\"+animal_name+'/'+date+'/'+'session_shifts.txt')\n",
    "session_timestamps=np.append([0],session_timestamps) # start the first timestamp at 0\n",
    "session_timestamps_down=session_timestamps*downsampled_res\n",
    "\n",
    "\n",
    "for session_idx_i in range(len(session_idx)):\n",
    "    # generate reward arms files for the training session files\n",
    "    if session_names[session_idx_i]=='training1' or session_names[session_idx_i]=='training2':\n",
    "        np.savetxt(mbasedir+animal_name+'-'+date+'_'+session_names[session_idx_i]+'.reward_arms', reward_arms, fmt='%i',newline=\" \")\n",
    "    \n",
    "    # cut the eegh files according to the session timestamps and write them to the merged folder\n",
    "    start_cut=session_idx[session_idx_i][0]-1\n",
    "    end_cut=session_idx[session_idx_i][-1]\n",
    "    start_eegh=int(session_timestamps_down[start_cut]/sample_rate_res*sample_rate_eegh)\n",
    "    end_eegh=int(session_timestamps_down[end_cut]/sample_rate_res*sample_rate_eegh)\n",
    "\n",
    "    eegh_temp=eegh_merged[start_eegh:end_eegh,:]\n",
    "\n",
    "    eegh_temp.tofile(mbasedir+animal_name+'-'+date+'_'+session_names[session_idx_i]+'.eegh')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
